{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13. Advanced RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 14:36:41 WARN Utils: Your hostname, Khanhs-MAC.local resolves to a loopback address: 127.0.0.1; using 192.168.0.103 instead (on interface en0)\n",
      "24/08/30 14:36:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/30 14:36:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"5\")\\\n",
    "    .appName(\"Advanced RDDs\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCollection = \"Spark The Definitive Guide : Big Data Processing Made Simple\"\\\n",
    "    .split(\" \")\n",
    "\n",
    "words = spark.sparkContext.parallelize(myCollection, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key-Value Basics (Key-Value RDDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.map(lambda words: words (words.lower() , 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keyBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = words.keyBy(lambda word: word.lower()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping over Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('s', 'SPARK'),\n",
       " ('t', 'THE'),\n",
       " ('d', 'DEFINITIVE'),\n",
       " ('g', 'GUIDE'),\n",
       " (':', ':'),\n",
       " ('b', 'BIG'),\n",
       " ('d', 'DATA'),\n",
       " ('p', 'PROCESSING'),\n",
       " ('m', 'MADE'),\n",
       " ('s', 'SIMPLE')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.mapValues(lambda word: word.upper()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 'S'),\n",
       " ('s', 'P'),\n",
       " ('s', 'A'),\n",
       " ('s', 'R'),\n",
       " ('s', 'K'),\n",
       " ('t', 'T'),\n",
       " ('t', 'H'),\n",
       " ('t', 'E'),\n",
       " ('d', 'D'),\n",
       " ('d', 'E'),\n",
       " ('d', 'F'),\n",
       " ('d', 'I'),\n",
       " ('d', 'N'),\n",
       " ('d', 'I'),\n",
       " ('d', 'T'),\n",
       " ('d', 'I'),\n",
       " ('d', 'V'),\n",
       " ('d', 'E'),\n",
       " ('g', 'G'),\n",
       " ('g', 'U'),\n",
       " ('g', 'I'),\n",
       " ('g', 'D'),\n",
       " ('g', 'E'),\n",
       " (':', ':'),\n",
       " ('b', 'B'),\n",
       " ('b', 'I'),\n",
       " ('b', 'G'),\n",
       " ('d', 'D'),\n",
       " ('d', 'A'),\n",
       " ('d', 'T'),\n",
       " ('d', 'A'),\n",
       " ('p', 'P'),\n",
       " ('p', 'R'),\n",
       " ('p', 'O'),\n",
       " ('p', 'C'),\n",
       " ('p', 'E'),\n",
       " ('p', 'S'),\n",
       " ('p', 'S'),\n",
       " ('p', 'I'),\n",
       " ('p', 'N'),\n",
       " ('p', 'G'),\n",
       " ('m', 'M'),\n",
       " ('m', 'A'),\n",
       " ('m', 'D'),\n",
       " ('m', 'E'),\n",
       " ('s', 'S'),\n",
       " ('s', 'I'),\n",
       " ('s', 'M'),\n",
       " ('s', 'P'),\n",
       " ('s', 'L'),\n",
       " ('s', 'E')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.flatMapValues(lambda word: word.upper()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Keys and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 't', 'd', 'g', ':', 'b', 'd', 'p', 'm', 's']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark',\n",
       " 'The',\n",
       " 'Definitive',\n",
       " 'Guide',\n",
       " ':',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Processing',\n",
       " 'Made',\n",
       " 'Simple']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.values().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Simple']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.lookup(\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampleByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 't', 'd', 'g', 'b', 'o', 'c', 'l', 's', 'a', 'r', 'k', 'h', 'e', 'f', 'i', 'n', 'v', 'u', ':', 'm']\n",
      "{'p': 0.8053699136020446, 't': 0.2515320222285219, 'd': 0.42082925556196704, 'g': 0.6314819744921397, 'b': 0.3295621535213801, 'o': 0.7976391422061683, 'c': 0.5217491770914663, 'l': 0.6607649221389149, 's': 0.07936372031147565, 'a': 0.9036858749632595, 'r': 0.10187455947853974, 'k': 0.16997303984431789, 'h': 0.17703403463098788, 'e': 0.8229375057224789, 'f': 0.16040118020146232, 'i': 0.057989469012307504, 'n': 0.8087039416817501, 'v': 0.4128904850796872, 'u': 0.25143925741163864, ':': 0.6237706641260152, 'm': 0.8387484211043137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('t', 'The'), ('g', 'Guide'), ('m', 'Made')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "distinctChars = words.flatMap(lambda word: list(word.lower()))\\\n",
    "    .distinct()\\\n",
    "    .collect()\n",
    "print(distinctChars)\n",
    "sampleMap = dict(map(lambda c: (c, random.random()), distinctChars))\n",
    "print(sampleMap)\n",
    "words.map(lambda word: (word.lower()[0], word))\\\n",
    "    .sampleByKey(True, sampleMap, 6).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = words.flatMap(lambda word: word.lower())\n",
    "KVcharacters = chars.map(lambda letter: (letter, 1))\n",
    "def maxFunc(left, right):\n",
    "    return max(left, right)\n",
    "def addFunc(left, right):\n",
    "    return left + right\n",
    "nums = spark.sparkContext.parallelize(range(1, 31), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'s': 4,\n",
       "             'p': 3,\n",
       "             'a': 4,\n",
       "             'r': 2,\n",
       "             'k': 1,\n",
       "             't': 3,\n",
       "             'h': 1,\n",
       "             'e': 7,\n",
       "             'd': 4,\n",
       "             'f': 1,\n",
       "             'i': 7,\n",
       "             'n': 2,\n",
       "             'v': 1,\n",
       "             'g': 3,\n",
       "             'u': 1,\n",
       "             ':': 1,\n",
       "             'b': 1,\n",
       "             'o': 1,\n",
       "             'c': 1,\n",
       "             'm': 2,\n",
       "             'l': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Aggregation Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 3),\n",
       " ('t', 3),\n",
       " ('d', 4),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('o', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('s', 4),\n",
       " ('a', 4),\n",
       " ('r', 2),\n",
       " ('k', 1),\n",
       " ('h', 1),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('i', 7),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "KVcharacters.groupByKey().map(lambda row: (row[0], reduce(addFunc, row[1])))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 3),\n",
       " ('t', 3),\n",
       " ('d', 4),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('o', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('s', 4),\n",
       " ('a', 4),\n",
       " ('r', 2),\n",
       " ('k', 1),\n",
       " ('h', 1),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('i', 7),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.reduceByKey(addFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Aggregation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.aggregate(0, maxFunc, addFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 3\n",
    "nums.treeAggregate(0, maxFunc, addFunc, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregateByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 2),\n",
       " ('t', 2),\n",
       " ('d', 2),\n",
       " ('g', 2),\n",
       " ('b', 1),\n",
       " ('o', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('s', 3),\n",
       " ('a', 3),\n",
       " ('r', 1),\n",
       " ('k', 1),\n",
       " ('h', 1),\n",
       " ('e', 4),\n",
       " ('f', 1),\n",
       " ('i', 4),\n",
       " ('n', 1),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.aggregateByKey(0, addFunc, maxFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combineByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('p', [1, 1, 1]),\n",
       " ('b', [1]),\n",
       " ('l', [1]),\n",
       " ('a', [1, 1, 1, 1]),\n",
       " ('k', [1]),\n",
       " ('h', [1]),\n",
       " ('i', [1, 1, 1, 1, 1, 1, 1]),\n",
       " ('u', [1]),\n",
       " ('t', [1, 1, 1]),\n",
       " ('d', [1, 1, 1, 1]),\n",
       " ('g', [1, 1, 1]),\n",
       " ('o', [1]),\n",
       " ('s', [1, 1, 1, 1]),\n",
       " ('r', [1, 1]),\n",
       " ('f', [1]),\n",
       " ('v', [1]),\n",
       " ('c', [1]),\n",
       " ('e', [1, 1, 1, 1, 1, 1, 1]),\n",
       " ('n', [1, 1]),\n",
       " (':', [1]),\n",
       " ('m', [1, 1])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def valToCombiner(value):\n",
    "    return [value]\n",
    "\n",
    "\n",
    "def mergeValuesFunc(vals, valToAppend):\n",
    "    vals.append(valToAppend)\n",
    "    return vals\n",
    "\n",
    "\n",
    "def mergeCombinerFunc(vals1, vals2):\n",
    "    return vals1 + vals2\n",
    "\n",
    "\n",
    "outputPartitions = 6\n",
    "KVcharacters\\\n",
    "    .combineByKey(\n",
    "        valToCombiner,\n",
    "        mergeValuesFunc,\n",
    "        mergeCombinerFunc,\n",
    "        outputPartitions)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### foldByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 3),\n",
       " ('t', 3),\n",
       " ('d', 4),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('o', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('s', 4),\n",
       " ('a', 4),\n",
       " ('r', 2),\n",
       " ('k', 1),\n",
       " ('h', 1),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('i', 7),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.foldByKey(0, addFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x10cfd96a0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x10cfdbc50>)),\n",
       " ('t',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x10cfd9b80>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x10cfd92e0>)),\n",
       " ('d',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x10cfdbb00>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x10cfd9d00>)),\n",
       " ('g',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x10cfd8fe0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x10cfd8ce0>)),\n",
       " ('l',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x10cfdbec0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x10cfdbf50>))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinctChars = words.flatMap(lambda word: word.lower()).distinct()\n",
    "charRDD = distinctChars.map(lambda c: (c, random.random()))\n",
    "charRDD2 = distinctChars.map(lambda c: (c, random.random()))\n",
    "charRDD.cogroup(charRDD2).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyedChars = distinctChars.map(lambda c: (c, random.random()))\n",
    "outputPartitions = 10\n",
    "KVcharacters.join(keyedChars).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.join(keyedChars, outputPartitions).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 0),\n",
       " ('The', 1),\n",
       " ('Definitive', 2),\n",
       " ('Guide', 3),\n",
       " (':', 4),\n",
       " ('Big', 5),\n",
       " ('Data', 6),\n",
       " ('Processing', 7),\n",
       " ('Made', 8),\n",
       " ('Simple', 9)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRange = spark.sparkContext.parallelize(range(10), 2)\n",
    "words.zip(numRange).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.coalesce(1).getNumPartitions() # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[128] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.repartition(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repartitionAndSortWithinPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"../data/retail-data/all/\")\n",
    "rdd = df.coalesce(10).rdd\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4302, 4307]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partitionFunc(key):\n",
    "    import random\n",
    "    if key == 17850 or key == 12583:\n",
    "      return 0\n",
    "    else:\n",
    "      return random.randint(1,2)\n",
    "keyedRDD = rdd.keyBy(lambda row: row[6])\n",
    "keyedRDD\\\n",
    "    .partitionBy(3, partitionFunc)\\\n",
    "    .map(lambda x: x[0])\\\n",
    "    .glom()\\\n",
    "    .map(lambda x: len(set(x)))\\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "class SomeClass:\n",
    "    def __init__(self):\n",
    "        self.someValue = 0\n",
    "\n",
    "    def setSomeValue(self, i):\n",
    "        self.someValue = i\n",
    "        return self\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(range(1, 11)).map(lambda num: SomeClass().setSomeValue(num))\n",
    "\n",
    "result = rdd.collect()\n",
    "\n",
    "for obj in result:\n",
    "    print(obj.someValue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
