{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 20:35:35 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/06/29 20:35:35 INFO SharedState: Warehouse path is 'file:/Users/khanhnn/Developer/DE/spark/practice_spark/practice/spark-warehouse'.\n",
      "24/06/29 20:35:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Structured_API_overview\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 20:35:54 INFO CodeGenerator: Code generated in 328.313791 ms\n",
      "24/06/29 20:35:54 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/06/29 20:35:54 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/06/29 20:35:54 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/06/29 20:35:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/29 20:35:54 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/29 20:35:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/06/29 20:35:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)\n",
      "24/06/29 20:35:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 434.4 MiB)\n",
      "24/06/29 20:35:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.102:51196 (size: 5.1 KiB, free: 434.4 MiB)\n",
      "24/06/29 20:35:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585\n",
      "24/06/29 20:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/29 20:35:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/06/29 20:35:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.0.102, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/06/29 20:35:55 INFO CodeGenerator: Code generated in 51.756417 ms(0 + 1) / 1]\n",
      "24/06/29 20:35:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1683 bytes result sent to driver\n",
      "24/06/29 20:35:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 235 ms on 192.168.0.102 (executor driver) (1/1)\n",
      "24/06/29 20:35:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/06/29 20:35:55 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 0.926 s\n",
      "24/06/29 20:35:55 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/29 20:35:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "24/06/29 20:35:55 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 0.968879 s\n",
      "24/06/29 20:35:55 INFO CodeGenerator: Code generated in 28.983084 ms            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "|    10|\n",
      "|    11|\n",
      "|    12|\n",
      "|    13|\n",
      "|    14|\n",
      "|    15|\n",
      "|    16|\n",
      "|    17|\n",
      "|    18|\n",
      "|    19|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 20:35:56 INFO CodeGenerator: Code generated in 73.583208 ms\n",
      "24/06/29 20:35:56 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/06/29 20:35:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)\n",
      "24/06/29 20:35:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 434.4 MiB)\n",
      "24/06/29 20:35:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.102:51196 (size: 5.2 KiB, free: 434.4 MiB)\n",
      "24/06/29 20:35:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/29 20:35:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.0.102, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/06/29 20:35:56 INFO CodeGenerator: Code generated in 60.914792 ms\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1626 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 85 ms on 192.168.0.102 (executor driver) (1/1)\n",
      "24/06/29 20:35:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/06/29 20:35:56 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.099 s\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/29 20:35:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.109100 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|number_plus_10|\n",
      "+--------------+\n",
      "|            10|\n",
      "|            11|\n",
      "|            12|\n",
      "|            13|\n",
      "|            14|\n",
      "|            15|\n",
      "|            16|\n",
      "|            17|\n",
      "|            18|\n",
      "|            19|\n",
      "|            20|\n",
      "|            21|\n",
      "|            22|\n",
      "|            23|\n",
      "|            24|\n",
      "|            25|\n",
      "|            26|\n",
      "|            27|\n",
      "|            28|\n",
      "|            29|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 20:35:56 INFO CodeGenerator: Code generated in 59.248792 ms\n",
      "24/06/29 20:35:56 INFO SparkContext: Starting job: collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Got job 2 (collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7) with 8 output partitions\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7)\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7), which has no missing parents\n",
      "24/06/29 20:35:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.7 KiB, free 434.4 MiB)\n",
      "24/06/29 20:35:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.4 MiB)\n",
      "24/06/29 20:35:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.102:51196 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "24/06/29 20:35:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))\n",
      "24/06/29 20:35:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.0.102, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (192.168.0.102, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (192.168.0.102, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (192.168.0.102, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (192.168.0.102, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7) (192.168.0.102, executor driver, partition 5, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8) (192.168.0.102, executor driver, partition 6, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9) (192.168.0.102, executor driver, partition 7, PROCESS_LOCAL, 7740 bytes) \n",
      "24/06/29 20:35:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 5.0 in stage 2.0 (TID 7)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 4.0 in stage 2.0 (TID 6)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 6.0 in stage 2.0 (TID 8)\n",
      "24/06/29 20:35:56 INFO Executor: Running task 7.0 in stage 2.0 (TID 9)\n",
      "24/06/29 20:35:56 INFO CodeGenerator: Code generated in 68.708792 ms\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 4.0 in stage 2.0 (TID 6). 1488 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1488 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 1541 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 1488 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 7.0 in stage 2.0 (TID 9). 1548 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 5.0 in stage 2.0 (TID 7). 1488 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 6.0 in stage 2.0 (TID 8). 1488 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 1488 bytes result sent to driver\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 229 ms on 192.168.0.102 (executor driver) (1/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 235 ms on 192.168.0.102 (executor driver) (2/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 230 ms on 192.168.0.102 (executor driver) (3/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 231 ms on 192.168.0.102 (executor driver) (4/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 229 ms on 192.168.0.102 (executor driver) (5/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 230 ms on 192.168.0.102 (executor driver) (6/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 229 ms on 192.168.0.102 (executor driver) (7/8)\n",
      "24/06/29 20:35:56 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 231 ms on 192.168.0.102 (executor driver) (8/8)\n",
      "24/06/29 20:35:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/06/29 20:35:56 INFO DAGScheduler: ResultStage 2 (collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7) finished in 0.256 s\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/29 20:35:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "24/06/29 20:35:56 INFO DAGScheduler: Job 2 finished: collect at /var/folders/2y/q6ddzlk97yv4jfwcmb5byk8h0000gn/T/ipykernel_78959/3432057235.py:7, took 0.265525 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(id=0), Row(id=1)]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(500).toDF(\"number\")\n",
    "transformedDf = df.select((df[\"number\"] + 10).alias(\"number_plus_10\"))\n",
    "\n",
    "df.show()\n",
    "transformedDf.show()\n",
    "\n",
    "spark.range(2).collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "divisBy2 = myrange"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
